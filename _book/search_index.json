[["speedtips.html", "Chapter 12 Some Tips to make R code faster 12.1 Use Latest version of R 12.2 Benchmark the findings 12.3 Algorithm matters more than language 12.4 Read the function 12.5 use [[ instead of [ when you can 12.6 Use Conditionals to break computations 12.7 Use simple functions", " Chapter 12 Some Tips to make R code faster Make it work, then make it beautiful, then if you really, really have to, make it fast. 90 percent of the time, if you make it beautiful, it will already be fast. So really, just make it beautiful!  Joe Armstrong In IT sector speed is very important. People rewrite tons of algorithms back again in c, c++, go and java. Just to gain that milliseconds or may be microseconds performance over one another. When you compared to these languages R is a very slow language. If you really need to get nanosecond level of optimization in R that are not possible without going to Rcpp; which by the way is a very easy wrapper for R user around C++. But still R code can be optimized to a level where you can get production level efficiency in R without too much trouble. And R is not slow compared to interpreted languages like python, Javascript, ruby etc 12.1 Use Latest version of R Each iteration of R is improving something to gain more speed with less and less memory. Its always useful if you need more speed to switch to Latest version of R and see if you get any speed gains. In general if you are using old versions of R or old functions that are deprecated and are no longer recommended by switching to a new version or new methods you will get a speed advantage for sure. Constant criticism that R is slow has made R to work in this respect and R is evolving according to the needs of time. There is not much to add here. If possible use the latest version, packages or methods mostly they might have more speed. 12.2 Benchmark the findings R is very obscure language there are no direct rules for speed gains. You might think you are making the code fast but in turn you could make it slow. The worst part about R is that you can write very very very slow code in R without realizing what are you missing. same R code can run 1K times faster when optimized. R is a very easy language to write slow code in. This is something you should keep in mind while writing the code. This is the reason you should benchmark your options, It may not give you much speed improvement, it may not give you any speed improvement at all. If you want to optimize R you must learn to benchmark the options. I would not go in details but microbenchmark is the best package for this task. Other packages have too many assumptions. 12.3 Algorithm matters more than language I see many people who write R for a single project and than because they cant make it run fast they switch to other languages like python mostly because they have read a few blog post written 5 to 10 years ago on how slow R is. In IT sector speed matters most and I would agree that if you could save a few milliseconds just by following a few basic rules please do that. Because when you create a shiny App or a Plumber API which many people hit at the same time every millisecond counts. But Dont get occupied by optimizing your code before it starts to work. Let me give you a basic structure, if your API can handle 40-50 requests per second on a single core you are at very high speed. Which means 20 to 30ms for each request. Usually network latency and disk caching and talking to DB etc takes more time. APIs mostly go from 200 to 500 ms per second in complex web apps. And R may not be the fastest language in the world but it sure can reach this level with minimum effort possible. Rest is all about scaling your app. So before you think about switching the language or saying that R in general is a slow language ask yourself have you optimized your code yet. Because if you dont optimize your code it doesnt matter what language you write it in. It will always be slow. Let me beat c++ with R and show you what I mean. Lets understand this by a very simple example. Lets start with the worst way you could code in any language called recursive functions and mark my words Never Use Recursive Functions. You are always better off without them. Lets try to see if we can find the good old fibonacci numbers and first 30 of them. We will write them in R and C++ alike. recurse_fib_r &lt;- function(fnum){ if(fnum &lt;= 1) { return(fnum) } else { return( recurse_fib_r(fnum-1) + recurse_fib_r(fnum-2) ) } } #include &lt;Rcpp.h&gt; //[[Rcpp::export]] int recurse_fib_rcpp(int fnum){ if(fnum &lt;= 1) { return(fnum) ; } else { return recurse_fib_rcpp( fnum - 1 ) + recurse_fib_rcpp( fnum - 2 ) ; } } lets compare both the functions now. microbenchmark::microbenchmark( mapply( recurse_fib_rcpp, 1:30 ), mapply( recurse_fib_r, 1:30 ), times = 10 ) ## Unit: milliseconds ## expr min lq mean median ## mapply(recurse_fib_rcpp, 1:30) 8.865901 9.265701 10.61928 10.84065 ## mapply(recurse_fib_r, 1:30) 4194.249101 4308.555201 4482.41654 4347.51080 ## uq max neval cld ## 11.7522 12.2191 10 a ## 4656.2668 5062.3585 10 b While c++ is still at milliseconds R has reached to seconds and that too for only 30 fibonacci numbers. This is not acceptable at any level you work on. Even if you are writing basic scripts this is not permissible to be sitting on your computer at all. Lets try to save memory by caching the results of previous operations. Lets try to save computation by using memoise package for caching intermediate results. mem_fib_r &lt;- function(fnum){ if(fnum &lt;= 1) { return(fnum) } else { return( memoised_fib_r(fnum - 1) + memoised_fib_r( fnum - 2) ) } } memoised_fib_r &lt;- memoise::memoise(mem_fib_r) Lets compare it with c++ microbenchmark::microbenchmark( mapply( recurse_fib_rcpp, 1:30 ), mapply( memoised_fib_r, 1:30 ), times = 10 ) ## Unit: milliseconds ## expr min lq mean median uq ## mapply(recurse_fib_rcpp, 1:30) 7.909201 8.848201 10.069091 9.854451 11.660100 ## mapply(memoised_fib_r, 1:30) 1.536400 1.688601 5.157291 1.762851 1.912001 ## max neval cld ## 12.9123 10 a ## 35.6415 10 a We have beat the c++ just by a very simple optimization. But If we write a simple function that doesnt use recursion we can still get better performance. Lets write a better algorithm by writing a loop. save_fib_r &lt;- function(fnum){ fnum &lt;- fnum + 1 vec &lt;- integer(fnum) vec[[2]] &lt;- 1 if(fnum &gt; 2){ for(i in 3:fnum){ vec[[i]] &lt;- vec[[ i - 1]] + vec[[ i - 2]] } } return(vec[[fnum]]) } Lets compare the results. microbenchmark::microbenchmark( mapply( recurse_fib_rcpp, 1:30 ), mapply( save_fib_r, 1:30 ), times = 10 ) ## Unit: microseconds ## expr min lq mean median uq ## mapply(recurse_fib_rcpp, 1:30) 8186.801 8862.602 9768.901 9772.9515 10284.101 ## mapply(save_fib_r, 1:30) 110.901 116.302 753.151 163.2505 179.201 ## max neval cld ## 12392.501 10 b ## 6193.801 10 a Now we are beating it with around 40x speed or more. But I think we can do better. This functions is vectorized but I am only asking for a single number I am doing the same calculations multiple time inside mapply function. If instead of using mapply I call the entire vec directly I will save computation. save_vec_fib_r &lt;- function(fnum){ vec &lt;- integer(fnum) vec[[2]] &lt;- 1 if(fnum &gt; 2){ for(i in 3:fnum){ vec[[i]] &lt;- vec[[ i - 1]] + vec[[ i - 2]] } } return(vec) } Now lets compare the differences microbenchmark::microbenchmark( mapply( save_fib_r, 1:1e3 ), save_vec_fib_r(1e3), times = 10 ) ## Unit: microseconds ## expr min lq mean median uq ## mapply(save_fib_r, 1:1000) 76844.201 79914.201 82003.021 81661.9520 83565.601 ## save_vec_fib_r(1000) 104.801 110.401 713.211 195.8515 299.001 ## max neval cld ## 91225.3 10 b ## 5395.8 10 a Now the difference is not only huge but we are calculating 1000 fibonacci numbers instead of just 30 we were working on previously. But I agree that I didnt gave c++ a chance. Languages have come and gone c++ have stood the test of time. Its the fastest language there is and R is nowhere close to it. I was just trying to compare an optimized version with an un-optimized one. Lets rewrite this same function in Rcpp just to see how far we are from the fastest programming language. #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] IntegerVector fib_rcpp(int fnum){ IntegerVector vec(fnum); vec[0] = 0; vec[1] = 1; if(fnum &gt; 1){ for(int i = 2; i &lt; fnum; ++i) { vec[i] = vec[ i - 1] + vec[ i - 2]; } } return vec; } microbenchmark::microbenchmark( fib_rcpp(1e5), save_vec_fib_r(1e5) ) ## Unit: microseconds ## expr min lq mean median uq ## fib_rcpp(1e+05) 181.401 333.651 592.3431 393.101 471.0515 ## save_vec_fib_r(1e+05) 12579.702 15117.602 17919.0970 17075.801 19382.3005 ## max neval cld ## 11609.3 100 a ## 30924.2 100 b So optimized R is about 28-30 times slower than the optimized rcpp code, which is a very good spot to be at. And to top it off now we are working on 1e5 numbers and that too within milliseconds in R. I wouldnt loose a sleep over it. So always try to optimize the language before going anywhere else. R is the most easiest language to write slow code in but the code can be optimized to 1000x easily with a few hacks like I just did. 12.4 Read the function You may assume just because you are using a base function that would be optimized to the core and thus it will be fastest solution out there. However thats far from truth sometime base R functions are overextended to check a few basic assumptions. You should get into a habit of reading the code. Its beneficial for debugging and for optimization as well. Let start small, R has a built in function by name replace and it does exactly what is intended from it it replaces a value from an index of a vector. But lets read it. replace ## function (x, list, values) ## { ## x[list] &lt;- values ## x ## } ## &lt;bytecode: 0x00000000084f4e98&gt; ## &lt;environment: namespace:base&gt; Its no more than a basic function you could write yourself. Lets check another one of my favorite function. stopifnot ## function (..., exprs, exprObject, local = TRUE) ## { ## n &lt;- ...length() ## if ((has.e &lt;- !missing(exprs)) || !missing(exprObject)) { ## if (n || (has.e &amp;&amp; !missing(exprObject))) ## stop(&quot;Only one of &#39;exprs&#39;, &#39;exprObject&#39; or expressions, not more&quot;) ## envir &lt;- if (isTRUE(local)) ## parent.frame() ## else if (isFALSE(local)) ## .GlobalEnv ## else if (is.environment(local)) ## local ## else stop(&quot;&#39;local&#39; must be TRUE, FALSE or an environment&quot;) ## E1 &lt;- if (has.e &amp;&amp; is.call(exprs &lt;- substitute(exprs))) ## exprs[[1]] ## cl &lt;- if (is.symbol(E1) &amp;&amp; E1 == quote(`{`)) { ## exprs[[1]] &lt;- quote(stopifnot) ## exprs ## } ## else as.call(c(quote(stopifnot), if (!has.e) exprObject else as.expression(exprs))) ## names(cl) &lt;- NULL ## return(eval(cl, envir = envir)) ## } ## Dparse &lt;- function(call, cutoff = 60L) { ## ch &lt;- deparse(call, width.cutoff = cutoff) ## if (length(ch) &gt; 1L) ## paste(ch[1L], &quot;....&quot;) ## else ch ## } ## head &lt;- function(x, n = 6L) x[seq_len(if (n &lt; 0L) max(length(x) + ## n, 0L) else min(n, length(x)))] ## abbrev &lt;- function(ae, n = 3L) paste(c(head(ae, n), if (length(ae) &gt; ## n) &quot;....&quot;), collapse = &quot;\\n &quot;) ## for (i in seq_len(n)) { ## r &lt;- ...elt(i) ## if (!(is.logical(r) &amp;&amp; !anyNA(r) &amp;&amp; all(r))) { ## dots &lt;- match.call()[-1L] ## if (is.null(msg &lt;- names(dots)) || !nzchar(msg &lt;- msg[i])) { ## cl.i &lt;- dots[[i]] ## msg &lt;- if (is.call(cl.i) &amp;&amp; identical(cl.i[[1]], ## quote(all.equal)) &amp;&amp; (is.null(ni &lt;- names(cl.i)) || ## length(cl.i) == 3L || length(cl.i &lt;- cl.i[!nzchar(ni)]) == ## 3L)) ## sprintf(gettext(&quot;%s and %s are not equal:\\n %s&quot;), ## Dparse(cl.i[[2]]), Dparse(cl.i[[3]]), abbrev(r)) ## else sprintf(ngettext(length(r), &quot;%s is not TRUE&quot;, ## &quot;%s are not all TRUE&quot;), Dparse(cl.i)) ## } ## stop(simpleError(msg, call = if (p &lt;- sys.parent(1L)) ## sys.call(p))) ## } ## } ## invisible() ## } ## &lt;bytecode: 0x00000000155acc20&gt; ## &lt;environment: namespace:base&gt; Again its basic R function, a huge one though. I wouldnt recommend you to rewrite it but if you just need a stop call on a basic condition you will be writing faster code with just simple if and stop function. Lets see that again in other base code. ifelse ## function (test, yes, no) ## { ## if (is.atomic(test)) { ## if (typeof(test) != &quot;logical&quot;) ## storage.mode(test) &lt;- &quot;logical&quot; ## if (length(test) == 1 &amp;&amp; is.null(attributes(test))) { ## if (is.na(test)) ## return(NA) ## else if (test) { ## if (length(yes) == 1) { ## yat &lt;- attributes(yes) ## if (is.null(yat) || (is.function(yes) &amp;&amp; identical(names(yat), ## &quot;srcref&quot;))) ## return(yes) ## } ## } ## else if (length(no) == 1) { ## nat &lt;- attributes(no) ## if (is.null(nat) || (is.function(no) &amp;&amp; identical(names(nat), ## &quot;srcref&quot;))) ## return(no) ## } ## } ## } ## else test &lt;- if (isS4(test)) ## methods::as(test, &quot;logical&quot;) ## else as.logical(test) ## ans &lt;- test ## len &lt;- length(ans) ## ypos &lt;- which(test) ## npos &lt;- which(!test) ## if (length(ypos) &gt; 0L) ## ans[ypos] &lt;- rep(yes, length.out = len)[ypos] ## if (length(npos) &gt; 0L) ## ans[npos] &lt;- rep(no, length.out = len)[npos] ## ans ## } ## &lt;bytecode: 0x0000000012d40888&gt; ## &lt;environment: namespace:base&gt; You might think ifelse is an optimized function in base R which is faster and optimized at the compiler level or interpretator level. But in fact if you read the function carefully and realize that its wasting on checking if you are passing an atomic vector and you are better off just using the last 5-6 lines of the function for a faster result. These are just the basic examples I could think out of my mind and there are tons of such example where you could optimize a function just by reading it and realizing you might not need so much of hassle in the first place. You could avoid meta-programming or non-standard evaluation of these functions just by rewriting some of its parts yourself. Reading the function will give you insight into whats it trying to do and is it fast enough for your use case and can you optimize it yourself. This thing applies to package level codes as well. And sometimes, not always its good to rewrite a custom solution for yourself. 12.5 use [[ instead of [ when you can x &lt;- data.frame(y = 1:1e4) microbenchmark::microbenchmark( &quot;[[&quot; = for(i in 1:1e4){ x$y[[i]] &lt;- i * 2 }, &quot;[&quot; = for(i in 1:1e4){ x$y[i] &lt;- i * 2 }, times = 10 ) ## Unit: milliseconds ## expr min lq mean median uq max neval cld ## [[ 143.9145 146.8341 160.4459 153.2965 155.4772 239.7528 10 a ## [ 144.3743 147.9331 159.5414 149.6783 155.1532 243.5469 10 a The difference is just in milliseconds but there is a difference non the less. If you use it precisely you might save a few millisecond when you need them with just a basic understanding that this too could help you at times. Best way to navigate a nested list is through [[ function by passing a character vector. Take this as an example x &lt;- list( y = list( z = list( a = 1 ) ) ) x[[c(&quot;y&quot;, &quot;z&quot;, &quot;a&quot;)]] ## [1] 1 or if you want to extract just z then x[[c(&quot;y&quot;, &quot;z&quot;)]] ## $a ## [1] 1 Its pretty helpful when you are working on json objects. take this for an example. x &lt;- list( y = list( list( z = 1 ), list( z = 2 ), list( z = 3 ), list( z = 4 ), list( z = 5 ) ) ) lapply(x$y,`[[`, &quot;z&quot;) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 ## ## [[4]] ## [1] 4 ## ## [[5]] ## [1] 5 These tricks will help you get some juice out of your machine. 12.6 Use Conditionals to break computations Somebody told me that the key to going BIG is doing as LITTLE as possible. R understands it and does that by default. Lets check an example where this is true. foo &lt;- function(x){ if( x == 10){ bar() } print(x) } foo(1) ## [1] 1 This function worked perfectly fine even though we havent created any function by name bar(). R havent evaluated that expression at all. In most of the other programming languages this is not possible at all. We will get an error During compilation of the function. But R lets you go away with this. And then there are other example like this if( TRUE || stop()) print(&quot;TRUE&quot;) ## [1] &quot;TRUE&quot; Here because || has lazy evaluation and doesnt read the next option unless first one is false you save time by doing it especially for complex equations. lazy_return &lt;- function(x){ y &lt;- 1:x return( y ) } eager_return &lt;- function(x){ y &lt;- integer(x) for(i in 1:x){ y[[i]] &lt;- i } return(y) } microbenchmark::microbenchmark( lazy_return(1e5), eager_return(1e5) ) ## Unit: nanoseconds ## expr min lq mean median uq max ## lazy_return(1e+05) 200 401 24377.03 851.5 2251.5 2242400 ## eager_return(1e+05) 3885101 4590451 5250495.88 4982601.0 5725050.0 10396801 ## neval cld ## 100 a ## 100 b ALTREP based vectors have the same effect as well. R hasnt started evaluating y in function lazy_return while it evaluated them in eager_return. Just because y are not evaluated in lazy_return while they are evaluated in the eager_return. x &lt;- lazy_return(1e3) y &lt;- eager_return(1e3) .Internal(inspect(x)) ## @0x00000000081d13b8 13 INTSXP g0c0 [REF(65535)] 1 : 1000 (compact) .Internal(inspect(y)) ## @0x0000000005e03780 13 INTSXP g0c7 [REF(2)] (len=1000, tl=0) 1,2,3,4,5,... People normally assume that for loops in R are very slow this is the reason eager_return is slow. But when you inspect the internal structure of both x and y you will see that x is a compact representation of number 1:1000 and thus its not using memory and its not even evaluated yet. While Y is a full fledged vector with all the numbers from 1 to 1000 stored in it. It consumes memory and time. While all the other calculations on these vectors will work exactly the same and it might not take as much time as you would assume. microbenchmark::microbenchmark( altrep = x + x, full_vector = y + y ) ## Unit: microseconds ## expr min lq mean median uq max neval cld ## altrep 1.9 2.101 3.40503 2.2505 3.001 23.901 100 a ## full_vector 1.8 2.051 2.64198 2.1020 2.651 13.001 100 a Other such example would be not evaluating a promise until its needed. In very simple terms R divides every operations into promises that have to be evaluated at a later stage and only when they are needed, Otherwise they might not be evaluated at all. func &lt;- function(x){ function(){ eager_return(x) } } x &lt;- 10 a &lt;- func(x) x &lt;- 12 a() ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 instead of 10 which we used when we created a it actually produced 12 because it didnt started evaluating the values until it actually had to evaluate the function. Lets take another example for this. lazy_func &lt;- function(x){ if(x &gt; 10){ eval_foo(x) } else if( x &lt; 0){ eval_bar(x) } else{ x } } lazy_func(5) ## [1] 5 This function worked fine even though there is no eval_foo and eval_bar function created here. R simply ignores the evaluation until needed. If the value lies above 10 or below 0 it will create an error saying there is no such function available for R to evaluate. lazy_func(11) ## Error in eval_foo(x): could not find function &quot;eval_foo&quot; microbenchmark::microbenchmark( shell = order(1:1e5,method = &quot;shell&quot;), radix = order(1:1e5,method = &quot;radix&quot;) ) ## Unit: microseconds ## expr min lq mean median uq max neval cld ## shell 1.801 1.901 2.27596 2.001 2.100 26.601 100 a ## radix 1.800 1.901 1.98404 2.001 2.002 2.401 100 a microbenchmark::microbenchmark( shell = order(1:1e3, method = &quot;shell&quot;), radix = order(1:1e3, method = &quot;radix&quot;) ) ## Unit: microseconds ## expr min lq mean median uq max neval cld ## shell 2 2.101 2.24198 2.201 2.301 5.900 100 a ## radix 2 2.100 2.32796 2.101 2.201 18.301 100 a if( TRUE || stop()) print(&quot;true&quot;) ## [1] &quot;true&quot; 12.7 Use simple functions "]]
